{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9cff0b",
   "metadata": {},
   "source": [
    "## Preprocesamiento de noticias con Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f2062",
   "metadata": {},
   "source": [
    "### Importar Librerias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d778cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji tweet-preprocessor tqdm -q\n",
    "!python -m nltk.downloader punkt -q\n",
    "!python -m nltk.downloader averaged_perceptron_tagger -q\n",
    "!python -m nltk.downloader stopwords -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd03a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "import json\n",
    "import preprocessor as tweet_preprocesor\n",
    "tweet_preprocesor.set_options(\n",
    "    tweet_preprocesor.OPT.ESCAPE_CHAR,\n",
    "    tweet_preprocesor.OPT.URL,\n",
    "    tweet_preprocesor.OPT.URL)\n",
    "\n",
    "import nltk\n",
    "STOPWORDS = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,size, length,col\n",
    "from pyspark.sql.types import StringType,DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681710c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/21 00:49:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"20g\") \\\n",
    "    .appName('my-cool-app') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b783292",
   "metadata": {},
   "source": [
    "### Cargar la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5baac8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': {'$oid': '611d9fe1049812a18b13a8dd'},\n",
       " 'topic': 'cultura',\n",
       " 'text': '',\n",
       " 'title': \"El vallenato con guitarra de los hijos de 'La celosa'\",\n",
       " 'year': 2020,\n",
       " 'month': 12,\n",
       " 'day': 7,\n",
       " 'key': 'cultura-musica-y-libros-vallenatos-de-el-trio-de-oro-32677',\n",
       " 'url': 'http://www.eltiempo.com//cultura/musica-y-libros/vallenatos-de-el-trio-de-oro-32677'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('news_new_format_2021-08-18.json','r',encoding='utf8') as f:\n",
    "    news = f.readlines()\n",
    "\n",
    "news = [json.loads(a.replace('\\n','')) for a in news]\n",
    "news[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8b0aa",
   "metadata": {},
   "source": [
    "### Limpieza inicial de los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eef00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(news[0].keys())\n",
    "data = [[value for key,value in doc.items()] for doc in news] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b395bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, features)\n",
    "df=df.filter(length(col('text'))>0)\n",
    "df=df.dropDuplicates(['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754fbc5",
   "metadata": {},
   "source": [
    "### Prepocesamiento de las noticias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e679fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text,tokenize=False,demojize=True,only_nouns=False):\n",
    "    data = tweet_preprocesor.clean(text)\n",
    "    data = re.sub(r'[,!?;-]+', '.', text)\n",
    "    data = nltk.word_tokenize(data)  # tokenize string to words\n",
    "    data = [ ch.lower() for ch in data\n",
    "             if ch.isalpha()\n",
    "             or ch == '.'\n",
    "             or emoji.get_emoji_regexp().search(ch)\n",
    "           ]\n",
    "    if demojize:\n",
    "      data = [ emoji.demojize(ch) \n",
    "               if emoji.get_emoji_regexp().search(ch)\n",
    "               else ch\n",
    "               for ch in data\n",
    "      ]\n",
    "    if only_nouns:\n",
    "      is_noun = lambda pos: pos[:2] in ('NN')\n",
    "      data = [\n",
    "              word for (word, post) in \n",
    "              nltk.pos_tag(data) if \n",
    "              is_noun(post) and\n",
    "              word not in STOPWORDS\n",
    "      ]\n",
    "    if not tokenize:\n",
    "      data = \" \".join(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc65dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_udf=udf(clean_text,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f94f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn('text_clean',clean_text_udf(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f7ad2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/21 01:00:46 WARN TaskSetManager: Stage 6 contains a task of very large size (161144 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|          text_clean|\n",
      "+--------------------+--------------------+\n",
      "|A Mintic, el papá...|a mintic . el pap...|\n",
      "|Adriana Lucía es ...|adriana lucía es ...|\n",
      "|Alrededor del mun...|alrededor del mun...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('text','text_clean').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12630f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
